{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adrian Zaręba | 320672\n",
    "# <span style=\"color:#458dc8\"> Zagłębienie się w Sieci Kohonena (SOM)<span>\n",
    "\n",
    "W tym dokumencie przyjrzymy się bliżej sieciom Kohonena, znane również jako Samoorganizujące się Mapy (SOM). Przejdziemy od teoretycznych podstaw, przez praktyczną implementację ich unikalnych właściwości, aż po zastosowania sieci w rozwiązywaniu realnych zadań (KOH2).\n",
    "\n",
    "## Spis treści\n",
    "1. [Opis Teoretyczny](#1-opis-teoretyczny) \n",
    "2. [Bazowa Implementacja](#2-bazowa-implementacja)\n",
    "3. [Wgląd na finalną klasę](#3-finalna-klasa)\n",
    "4. [Funkcje sąsiedztwa](#4-Funkcje-sąsiedztwa)\n",
    "5. [Funkcje wygaszające](#5-wygaszanie)\n",
    "6. [Warianty topologii](#7-warianty-topologii)\n",
    "7. [Wizualizacje + Metody oceny](#8-wizualizacje)\n",
    "\n",
    "## <span style=\"color:#458dc8\"> 1. Opis Teoretyczny <span>\n",
    "\n",
    "Sieci Kohonena są specjalnym typem sieci neuronowych, które skupiają się na nauce bez nadzoru i tworzeniu topologicznych map wejść, co pozwala na wizualizację dużych ilości danych w uproszczonej formie. SOM działają poprzez organizowanie siebie w przestrzeni dwuwymiarowej lub trójwymiarowej, co umożliwia łatwą analizę wzorców i klasteryzację danych (w naszym przypadku skupimy się na dwuwymiarowej).\n",
    "\n",
    "### Model Matematyczny Neuronu w SOM\n",
    "\n",
    "Podobnie jak inne sieci neuronowe, SOM operuje na zbiorze neuronów. Jednak w przeciwieństwie do tradycyjnych sieci, neurony w SOM są rozmieszczone na mapie topologicznej, gdzie każdy neuron jest bezpośrednio powiązany z określonymi sąsiadami, tworząc strukturę siatki.\n",
    "\n",
    "$$ s = \\arg\\min_i \\| x - w_i \\|^2 $$\n",
    "\n",
    "### Składniki Modelu\n",
    "\n",
    "- $s$ to zwycięzca, czyli neuron, który najbardziej pasuje do aktualnie przetwarzanego wejścia $x$.\n",
    "  \n",
    "- $x$ to aktualne wejście do sieci, które jest porównywane z wagami neuronów w celu znalezienia zwycięzcy.\n",
    "\n",
    "- $w_i$ to wagi i-tego neuronu na mapie. Wagi te są dostosowywane w procesie uczenia, co pozwala mapie samoorganizować się w sposób odzwierciedlający topologiczną strukturę danych wejściowych.\n",
    "\n",
    "### <span style=\"color:lightblue\"> Przydatna rada: <span>\n",
    "W przeciwieństwie do sieci MLP, SOM mogą być nieco trudniejsze do 'wyobrażenia' (przynajmniej w moim wypadku). Warto jednak skupić uwagę na podstawy działania przez obliczenia matematyczne, co może zająć nieco więcej czasu, jednak na pewno warto.\n",
    "\n",
    "### <span style=\"color:orange\"> Uwaga: <span>\n",
    "Podczas implementacji i eksploracji SOM, ważne jest, aby zrozumieć, że choć algorytm jest prosty w teorii, jego efektywność w praktyce może zależeć od wielu czynników, takich jak wybór parametrów uczących, inicjalizacja wag oraz sposób przetwarzania danych wejściowych. Dopasowanie tych elementów do specyficznych wymagań zadania jest kluczowe dla osiągnięcia optymalnych wyników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#458dc8\"> 2. Bazowa Implementacja <span>\n",
    "Spójrzmy na najprostszy szkielet naszej sieci KOH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KOH:\n",
    "    def __init__(self, m, n, dim):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.weights = np.random.rand(m, n, dim)\n",
    "\n",
    "    def get_bmu(self, x):\n",
    "        distances = np.linalg.norm(self.weights - x, axis=-1)\n",
    "        return np.unravel_index(np.argmin(distances), (self.m, self.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opis Działania\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Inicjacja Siatki Kohonena <span>\n",
    "\n",
    "Przed rozpoczęciem działania sieci Kohonena musimy ją zainicjować. Metoda `__init__` przyjmuje trzy parametry:\n",
    "- `m` oraz `n`, które określają wymiary siatki Kohonena (liczbę wierszy i kolumn odpowiednio).\n",
    "- `dim`, który reprezentuje wymiarowość danych wejściowych.\n",
    "\n",
    "Podczas inicjacji, dla każdej jednostki w siatce losowane są początkowe wagi o wymiarze `dim`. Te wagi stanowią punkty w przestrzeni, które sieć będzie adaptować podczas procesu uczenia.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Uczenie i Adaptacja Wagi <span>\n",
    "\n",
    "Głównym celem sieci Kohonena jest samoorganizacja w celu zgrupowania podobnych danych wejściowych. W trakcie procesu uczenia, gdy podawany jest wektor wejściowy `x`, poszukujemy jednostki w siatce, której wagi najlepiej pasują do tego wektora. Ta jednostka nazywana jest Najlepszą Jednostką Dopasowującą (BMU).\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Znajdowanie BMU <span>\n",
    "\n",
    "Metoda `get_bmu` jest kluczowa w procesie uczenia. Przechodzi przez każdą jednostkę w siatce i oblicza odległość między wagami danej jednostki a wektorem wejściowym `x`. Następnie wybiera jednostkę o najmniejszej odległości, co odpowiada BMU. BMU wskazuje jednostkę w siatce, której wagi są najbliższe wektorowi wejściowemu.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Adaptacja Wag <span>\n",
    "\n",
    "Po znalezieniu BMU, wagi tej jednostki oraz wag jej sąsiadów są dostosowywane, aby bardziej odpowiadały wektorowi wejściowemu. To dostosowanie zachodzi na zasadzie przyciągania wag w kierunku wektora wejściowego, co pozwala na lepsze dopasowanie do danych.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Iteracyjne Uczenie <span>\n",
    "\n",
    "Proces znajdowania BMU i adaptacji wag jest iteracyjny. Dla każdego nowego wektora wejściowego sieć przeszukuje siatkę w poszukiwaniu BMU i dostosowuje wagi. Powtarzając ten proces dla wielu wektorów wejściowych, sieć samoorganizuje się, tworząc strukturę odpowiadającą rozkładowi danych w przestrzeni wejściowej.\n",
    "\n",
    "\n",
    "#### <span style=\"color:orange\"> Wyjaśnienie (skopiowane ze strony internetowej, pomocne) \"Na Chłopski Rozum\" <span>\n",
    "##### Cytuję: \"Wyobraź sobie sieć SOM jak mapę sklepów spożywczych w Twoim mieście. Każdy sklep ma swoje określone położenie na mapie. Kiedy masz listę zakupów (wektor danych wejściowych), szukasz najbliższego sklepu (BMU), aby zrobić zakupy. Gdy znajdziesz najbliższy sklep, idziesz tam i robisz zakupy (aktualizujesz wagi). Następnie, kiedy masz kolejną listę zakupów, powtarzasz ten proces, ucząc się, które sklepy są najlepiej dostosowane do Twoich potrzeb. W rezultacie, z czasem Twoje zakupy stają się coraz bardziej efektywne, ponieważ wiesz, które sklepy mają to, czego potrzebujesz, i są najbliżej Ciebie.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#458dc8\"> 3. Wgląd na finalną klasę <span>\n",
    "Poniżej przedstawiona jest finalna klasa, na której bazował projekt. Posiada ona dużo funkcji w tym wizualizacyjne. W ramach teorii skupimy się jednak jedynie na najważniejszych fragmentach.\n",
    "### KOH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KOH:\n",
    "    def __init__(self, m, n, dim, alpha=0.3, sigma=None, lambda_=100, neighborhood_func=\"gaussian\", topology='rectangular'):\n",
    "        \"\"\"\n",
    "        Inicjuje KOH z podanymi parametrami.\n",
    "        Argumenty:\n",
    "            m (int): Liczba wierszy w siatce KOH.\n",
    "            n (int): Liczba kolumn w siatce KOH.\n",
    "            dim (int): Wymiarowość danych wejściowych.\n",
    "            alpha (float): Początkowa szybkość uczenia.\n",
    "            sigma (float): Początkowa wielkość sąsiedztwa.\n",
    "            lambda_ (float): Stała czasowa do zanikania.\n",
    "            neighborhood_func (str): Typ funkcji sąsiedztwa (\"gaussian\" lub \"mexican_hat\").\n",
    "            topology (str): Wybranie topologii sieci.\n",
    "            weights (np.ndarray): Wagi siatki KOH.\n",
    "            alpha_decay (function): Funkcja zanikająca szybkość uczenia.\n",
    "            sigma_decay (float): Tempo zanikania sąsiedztwa.\n",
    "        \"\"\"\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma/100 if sigma is not None else max(m, n) / 2\n",
    "        self.lambda_ = lambda_\n",
    "        self.neighborhood_func = neighborhood_func\n",
    "        self.topology = topology\n",
    "        self.weights = np.random.rand(m, n, dim)\n",
    "        self.alpha_decay = lambda t: np.exp(-t / self.lambda_)\n",
    "        self.sigma_decay = 0.99\n",
    "\n",
    "\n",
    "    def get_bmu(self, x):\n",
    "        \"\"\"\n",
    "        Znajduje najlepszą jednostkę dopasowującą (BMU) dla podanego wektora wejściowego.\n",
    "        Argumenty:\n",
    "            x (np.ndarray): Wektor wejściowy.\n",
    "        Zwraca:\n",
    "            tuple: Współrzędne BMU w siatce KOH.\n",
    "        \"\"\"\n",
    "        distances = np.linalg.norm(self.weights - x, axis=-1)\n",
    "        return np.unravel_index(np.argmin(distances), (self.m, self.n))\n",
    "    \n",
    "\n",
    "    def hex_distance(self, a, b):\n",
    "        \"\"\"\n",
    "        Oblicza odległość między dwoma punktami w zależności od topologii siatki.\n",
    "        Argumenty:\n",
    "            a (tuple): Współrzędne punktu startowego (ax, ay).\n",
    "            b (tuple): Współrzędne punktu końcowego (bx, by).\n",
    "        Zwraca:\n",
    "            float: Obliczoną odległość między punktami w zależności od topologii.\n",
    "        Wyrzuca:\n",
    "            ValueError: Jeśli podana topologia nie jest obsługiwana (tylko 'rectangular' lub 'hexagonal').\n",
    "        \"\"\"\n",
    "        ax, ay = a\n",
    "        bx, by = b\n",
    "        if self.topology == 'rectangular':\n",
    "            return np.sqrt((ax - bx) ** 2 + (ay - by) ** 2)\n",
    "        elif self.topology == 'hexagonal':\n",
    "            dx = bx - ax\n",
    "            dy = by - ay\n",
    "            return max(abs(dx), abs(dy), abs(dx + dy))\n",
    "        else:\n",
    "            raise ValueError(\"Dostępne są tylko dwie topologie: rectangular | hexagonal\")\n",
    "\n",
    "\n",
    "    def get_neighborhood(self, bmu, sigma):\n",
    "        \"\"\"\n",
    "        Tworzy macierz sąsiedztwa wokół podanego BMU (Best Matching Unit) z wykorzystaniem określonej topologii.\n",
    "        Argumenty:\n",
    "            bmu (tuple): Współrzędne BMU w siatce KOH.\n",
    "            sigma (float): Bieżąca wielkość sąsiedztwa, określająca zakres, w jakim sąsiednie neurony są aktualizowane.\n",
    "        Zwraca:\n",
    "            np.ndarray: Macierz sąsiedztwa, gdzie wartości reprezentują wagę wpływu BMU na każdy neuron w siatce.\n",
    "        \"\"\"\n",
    "        d = np.zeros((self.m, self.n))\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                d[i, j] = self.hex_distance(bmu, (i, j))\n",
    "        if self.neighborhood_func == \"gaussian\":\n",
    "            return np.exp(-d / (2 * sigma ** 2))\n",
    "        elif self.neighborhood_func == \"mexican_hat\":\n",
    "            return (1 - d / (sigma ** 2)) * np.exp(-d / (2 * (sigma ** 2)))\n",
    "        else:\n",
    "            raise ValueError(\"Dostępne są tylko dwie funkcje: gaussian | mexican_hat\")\n",
    "\n",
    "\n",
    "    def update_weights(self, x, bmu, neighborhood):\n",
    "        \"\"\"\n",
    "        Aktualizuje wagi siatki KOH.\n",
    "        Argumenty:\n",
    "            x (np.ndarray): Wektor wejściowy.\n",
    "            bmu (tuple): Współrzędne BMU w siatce KOH.\n",
    "            neighborhood (np.ndarray): Funkcja sąsiedztwa skupiona wokół BMU.\n",
    "        \"\"\"\n",
    "        self.weights += self.alpha * neighborhood[..., None] * (x - self.weights)\n",
    "\n",
    "\n",
    "    def train(self, data, num_iterations, labels=None, show_estimated_time=False):\n",
    "        \"\"\"\n",
    "        Trenuje KOH na podanych danych.\n",
    "        Argumenty:\n",
    "            data (np.ndarray): Dane wejściowe.\n",
    "            num_iterations (int): Liczba iteracji treningowych.\n",
    "            show_estimated_time (bool): Opcja, czy wyświetlać estymowany czas wykonania.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            iteration_time_sum = 0\n",
    "            iteration_time_sq_sum = 0\n",
    "            for t in range(num_iterations):\n",
    "                iteration_start_time = time.time()\n",
    "                for x in data:\n",
    "                    bmu = self.get_bmu(x)\n",
    "                    neighborhood = self.get_neighborhood(bmu, self.sigma)\n",
    "                    self.update_weights(x, bmu, neighborhood)\n",
    "                self.alpha = self.alpha_decay(t)\n",
    "                self.sigma *= self.sigma_decay\n",
    "                iteration_end_time = time.time()\n",
    "                iteration_time = iteration_end_time - iteration_start_time\n",
    "                iteration_time_sum += iteration_time\n",
    "                iteration_time_sq_sum += iteration_time**2\n",
    "                if show_estimated_time:\n",
    "                    average_iteration_time = iteration_time_sum / (t + 1)\n",
    "                    estimated_total_time = average_iteration_time * (num_iterations - t - 1)\n",
    "                    print(f\"Iteracja {t+1}/{num_iterations} | alpha: {self.alpha:.4f} | sigma: {self.sigma:.4f} | \"\n",
    "                          f\"Estymowany czas pozostały: {estimated_total_time:.2f} sekund\", end='\\r')\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted. Finalizing...\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred: {e}\")\n",
    "        finally:\n",
    "            if labels is not None and len(labels) > 0:\n",
    "                label_map = self.assign_labels(data, labels)\n",
    "                accuracy = self.evaluate_accuracy(data, labels, label_map)\n",
    "                print(f\"\\nAccuracy: {accuracy:.4f}%\")\n",
    "            else:\n",
    "                print(f\"\\nFinal parameters | alpha: {self.alpha:.4f} | sigma: {self.sigma:.4f}\")\n",
    "\n",
    "    \n",
    "    def assign_labels(self, data, labels):\n",
    "        \"\"\"\n",
    "        Przypisuje etykiety do każdego neuronu na mapie Kohonena na podstawie dominującej etykiety najbliższych punktów danych.\n",
    "        Argumenty:\n",
    "            data (numpy.ndarray): Dane wejściowe.\n",
    "            labels (numpy.ndarray): Odpowiadające etykiety dla danych wejściowych.\n",
    "        Zwraca:\n",
    "            numpy.ndarray: Mapa etykiet przypisanych do neuronów na mapie Kohonena.\n",
    "        \"\"\"\n",
    "        label_map = np.zeros((self.m, self.n), dtype=int)\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                distances = np.linalg.norm(data - self.weights[i, j], axis=1)\n",
    "                closest_data_indices = np.argsort(distances)[:10]\n",
    "                common_labels = labels[closest_data_indices]\n",
    "                most_common = np.bincount(common_labels).argmax()\n",
    "                label_map[i, j] = most_common\n",
    "        return label_map\n",
    "\n",
    "\n",
    "    def plot_kohonen_map(self, label_map):\n",
    "        \"\"\"\n",
    "        Wyświetla mapę Kohonena z oznaczonymi klasami.\n",
    "        Argumenty:\n",
    "            label_map (numpy.ndarray): Mapa etykiet przypisanych do neuronów na mapie Kohonena.\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        label_map = label_map.astype(int)\n",
    "        cmap = plt.get_cmap('viridis', np.unique(label_map).max() + 1)\n",
    "        mat = ax.matshow(label_map, cmap=cmap)\n",
    "        cbar = plt.colorbar(mat, ticks=np.arange(np.min(label_map), np.max(label_map)+1))\n",
    "        plt.title(\"Mapa Kohonena z etykietami klas\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def evaluate_accuracy(self, test_data, test_labels, label_map):\n",
    "        \"\"\"\n",
    "        Ocenia dokładność klasyfikatora mapy Kohonena.\n",
    "        Argumenty:\n",
    "            test_data (numpy.ndarray): Dane testowe.\n",
    "            test_labels (numpy.ndarray): Odpowiadające etykiety dla danych testowych.\n",
    "            label_map (numpy.ndarray): Mapa etykiet przypisanych do neuronów na mapie Kohonena.\n",
    "        Zwraca:\n",
    "            float: Dokładność klasyfikatora mapy Kohonena.\n",
    "        \"\"\"\n",
    "        predicted_labels = []\n",
    "        for x in test_data:\n",
    "            bmu = self.get_bmu(x)\n",
    "            predicted_label = label_map[bmu]\n",
    "            predicted_labels.append(predicted_label)\n",
    "        accuracy = np.sum(predicted_labels == test_labels) / len(test_labels)\n",
    "        return accuracy\n",
    "    \n",
    "\n",
    "    def calculate_silhouette_score(self, data, labels=None):\n",
    "        \"\"\"\n",
    "        Oblicza Silhouette Score dla danych przetworzonych przez mapę Kohonena.\n",
    "        Argumenty:\n",
    "            data (np.ndarray): Dane wejściowe.\n",
    "            labels (np.ndarray): Etykiety klastrów, jeśli już przypisane; w przeciwnym razie zostaną przypisane na podstawie BMU.\n",
    "        Zwraca:\n",
    "            float: Wartość Silhouette Score.\n",
    "        \"\"\"\n",
    "        if labels is None:\n",
    "            labels = np.array([self.get_bmu(x) for x in data])\n",
    "            labels = labels[:, 0] * self.n + labels[:, 1]\n",
    "        return silhouette_score(data, labels)\n",
    "\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Przewiduje BMU dla każdego wektora wejściowego w danych.\n",
    "        Argumenty:\n",
    "            data (np.ndarray): Dane wejściowe.\n",
    "        Zwraca:\n",
    "            list: Lista BMU dla każdego wektora wejściowego.\n",
    "        \"\"\"\n",
    "        return [self.get_bmu(x) for x in data]\n",
    "\n",
    "\n",
    "    def plot_clusters(self, data, labels):\n",
    "        \"\"\"\n",
    "        Rysuje wykres punktów danych pogrupowanych w klastry.\n",
    "        Argumenty:\n",
    "            data (np.ndarray): Dane wejściowe.\n",
    "            labels (np.ndarray): Prawdziwe etykiety.\n",
    "        Zwraca:\n",
    "            dict: Słownik zawierający informacje o przypisaniu danych do klastrów.\n",
    "        \"\"\"\n",
    "        bmus = [self.get_bmu(x) for x in data]\n",
    "        label_dict = {tuple(bmu): labels[i] for i, bmu in enumerate(bmus)}\n",
    "        cluster_labels = [label_dict[tuple(bmu)] for bmu in bmus]\n",
    "        assignment_info = {i: f'Data row {i} assigned to cluster {cluster_labels[i]}' for i in range(len(data))}\n",
    "        for info in assignment_info.values():\n",
    "            print(info)\n",
    "        if data.shape[1] == 2:\n",
    "            plt.scatter(data[:, 0], data[:, 1], c=cluster_labels, cmap='viridis')\n",
    "            plt.title('Clustering')\n",
    "            plt.show()\n",
    "        elif data.shape[1] == 3:\n",
    "            fig = go.Figure(data=[go.Scatter3d(\n",
    "                x=data[:, 0],\n",
    "                y=data[:, 1],\n",
    "                z=data[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(size=5, color=cluster_labels, colorscale='Viridis', opacity=0.8)\n",
    "            )])\n",
    "            fig.update_layout(title='Clustering', scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'), width=1100, height=550)\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#458dc8\"> 4. Funkcje sąsiedztwa <span>\n",
    "\n",
    "W sieciach Kohonena, funkcje sąsiedztwa są kluczowymi elementami, które określają, jak bardzo neurony sąsiadujące z najlepiej dopasowaną jednostką (BMU) są modyfikowane podczas procesu uczenia. Te funkcje pomagają w regulowaniu wpływu BMU na swoje sąsiedztwo, co jest istotne dla prawidłowego rozmieszczenia i adaptacji wag neuronów na mapie cech. W klasie `KOH` mam zaimplementowane dwa typy funkcji sąsiedztwa: gaussowską i meksykański kapelusz.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Funkcja Gaussowska (Gaussian) <span>\n",
    "\n",
    "Funkcja Gaussowska to standardowa funkcja używana w algorytmie Kohonena do modelowania wpływu BMU na jej sąsiednie neurony. Jest definiowana jako:\n",
    "\n",
    "$$\n",
    "N(d, \\sigma) = \\exp\\left(-\\frac{d^2}{2 \\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "gdzie $d$ jest odległością od BMU do danego neuronu, a $\\sigma$ jest parametrem określającym wielkość sąsiedztwa, który z czasem maleje. Funkcja ta ma kształt dzwonu, co oznacza, że neurony bliżej BMU otrzymują silniejsze aktualizacje niż te dalsze.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Meksykański Kapelusz (Mexican Hat) <span>\n",
    "\n",
    "Funkcja meksykański kapelusz, znana również jako funkcja Ricker wavelet, jest mniej standardowym wyborem, ale oferuje ciekawą alternatywę, która nie tylko wzmacnia neurony blisko BMU, ale również tłumi te znajdujące się w umiarkowanej odległości, przed ponownym zwiększeniem wpływu dla dalszych neuronów. Jest definiowana jako:\n",
    "\n",
    "$$\n",
    "N(d, \\sigma) = (1 - \\frac{d^2}{\\sigma^2}) \\exp\\left(-\\frac{d^2}{2 \\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "To połączenie funkcji liniowej i gaussowskiej prowadzi do profilu, który przypomina meksykański kapelusz, stąd nazwa (nie wiem dlaczego, ale bardzo mnie ciekawił ten fakt). Funkcja ta może sprzyjać tworzeniu bardziej zróżnicowanych klastrów, ponieważ wzmacnia oddziaływanie zarówno bliskich, jak i niektórych dalszych neuronów, przy jednoczesnym tłumieniu wpływu neuronów pośrednich.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Implementacja <span>\n",
    "\n",
    "W klasie `KOH`, obie te funkcje są używane do generowania macierzy sąsiedztwa w metodzie `get_neighborhood`, która następnie jest wykorzystywana do aktualizacji wag w metodzie `update_weights`. Wybór funkcji sąsiedztwa (gaussowska czy meksykański kapelusz) wpływa na sposób, w jaki aktualizacje są stosowane do wag neuronów podczas treningu, co z kolei wpływa na ostateczny kształt mapy cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood(self, bmu, sigma):\n",
    "    d = np.zeros((self.m, self.n))\n",
    "    for i in range(self.m):\n",
    "        for j in range(self.n):\n",
    "            d[i, j] = self.hex_distance(bmu, (i, j))\n",
    "    if self.neighborhood_func == \"gaussian\":\n",
    "        return np.exp(-d / (2 * sigma ** 2))\n",
    "    elif self.neighborhood_func == \"mexican_hat\":\n",
    "        return (1 - d / (sigma ** 2)) * np.exp(-d / (2 * (sigma ** 2)))\n",
    "    else:\n",
    "        raise ValueError(\"Dostępne są tylko dwie funkcje: gaussian | mexican_hat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#458dc8\"> 5. Funkcje wygaszające <span>\n",
    "Funkcje wygaszające odgrywają kluczową rolę w algorytmach sieci Kohonena (SOM) poprzez kontrolowanie tempa uczenia się sieci w czasie. Zastosowanie tych funkcji pomaga w stabilizacji procesu uczenia, stopniowo zmniejszając wpływ każdego kolejnego wektora wejściowego, co pozwala na bardziej subtelne dostosowanie wag sieci w miarę jej \"dojrzewania\". W klasie `KOH` zaimplementowano dwie główne funkcje wygaszające dla szybkości uczenia (`alpha`) oraz wielkości sąsiedztwa (`sigma`).\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Funkcja wygaszająca dla szybkości uczenia (`alpha_decay`)\n",
    "\n",
    "Szybkość uczenia, `alpha`, jest jednym z najważniejszych parametrów w sieciach Kohonena, wpływającym na to, jak szybko sieć dostosowuje swoje wagi w odpowiedzi na każdy wektor wejściowy. Funkcja wygaszająca dla `alpha` jest zdefiniowana jako funkcja eksponencjalnego zaniku:\n",
    "\n",
    "$$\n",
    "\\alpha(t) = \\alpha_0 \\cdot e^{-\\frac{t}{\\lambda}}\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "- $\\alpha_0$ to początkowa wartość szybkości uczenia,\n",
    "- $t $ to numer iteracji,\n",
    "- $ \\lambda$ to stała czasowa, która kontroluje, jak szybko szybkość uczenia zanika w czasie.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Funkcja wygaszająca dla wielkości sąsiedztwa (`sigma_decay`)\n",
    "\n",
    "Wielkość sąsiedztwa, `sigma`, określa zakres przestrzenny, w którym BMU wpływa na swoje sąsiednie neurony. Funkcja wygaszająca dla `sigma` w klasie `KOH` jest zaimplementowana jako prosta funkcja mnożnikowa:\n",
    "\n",
    "$$\n",
    "\\sigma(t) = \\sigma_0 \\cdot d^{t}\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "- $ \\sigma_0 $ to początkowa wielkość sąsiedztwa,\n",
    "- $d$ to współczynnik zaniku, zazwyczaj ustawiany na wartość poniżej 1 (np. 0.99), co oznacza, że `sigma` z każdą iteracją maleje o 1%.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Implementacja\n",
    "\n",
    "Funkcje wygaszające są zaimplementowane w konstruktorze klasy `KOH` oraz używane w metodzie `train`, gdzie z każdą iteracją aktualizowane są wartości `alpha` i `sigma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, m, n, dim, alpha=0.3, sigma=None, lambda_=100, ...):\n",
    "    self.alpha = alpha\n",
    "    self.sigma = sigma / 100 if sigma is not None else max(m, n) / 2\n",
    "    self.lambda_ = lambda_\n",
    "    self.alpha_decay = lambda t: np.exp(-t / self.lambda_)\n",
    "    self.sigma_decay = 0.99\n",
    "\n",
    "def train(self, data, num_iterations, ...):\n",
    "    for t in range(num_iterations):\n",
    "        self.alpha = self.alpha_decay(t)\n",
    "        self.sigma *= self.sigma_decay\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#458dc8\"> 6. Warianty topologii <span>\n",
    "Topologia w sieciach Kohonena (SOM) odnosi się do sposobu rozmieszczenia neuronów oraz definicji sąsiedztwa między nimi. W naszej klasie `KOH` można wybrać jedną z dwóch topologii: prostokątną (rectangular) lub sześciokątną (hexagonal). Każda z nich wpływa na sposób interakcji neuronów, ich aktualizacji wag oraz ostateczną organizację mapy cech.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Topologia prostokątna (`rectangular`) <span>\n",
    "\n",
    "W topologii prostokątnej, neurony są ułożone w regularnej siatce dwuwymiarowej. Sąsiedztwo jest zdefiniowane w sposób ortogonalny, co oznacza, że każdy neuron (oprócz tych na brzegach) ma czterech bezpośrednich sąsiadów (góra, dół, lewo, prawo).\n",
    "\n",
    "##### <span style=\"color:lightblue\"> Obliczanie odległości <span>\n",
    "\n",
    "Odległość między neuronami jest mierzona standardowo, przy użyciu metryki euklidesowej:\n",
    "\n",
    "$$\n",
    "d(a, b) = \\sqrt{(ax - bx)^2 + (ay - by)^2}\n",
    "$$\n",
    "\n",
    "gdzie $ (ax, ay) $ i $ (bx, by) $ to współrzędne dwóch różnych neuronów na siatce.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Topologia sześciokątna (`hexagonal`) <span>\n",
    "\n",
    "Topologia sześciokątna jest bardziej złożona i pozwala na bliższe odwzorowanie naturalnych procesów grupowania, gdyż każdy neuron (oprócz tych na brzegach) ma sześciu sąsiadów. Taka konfiguracja zapewnia bardziej jednolite pokrycie przestrzeni i może prowadzić do bardziej homogenicznych map cech.\n",
    "\n",
    "##### <span style=\"color:lightblue\"> Obliczanie odległości <span>\n",
    "\n",
    "Odległość między neuronami w topologii sześciokątnej jest zwykle mierzona przy użyciu metryki maksymalnej:\n",
    "\n",
    "$$\n",
    "d(a, b) = \\max(|ax - bx|, |ay - by|, |ax + ay - bx - by|)\n",
    "$$\n",
    "\n",
    "Ten sposób obliczania odległości uwzględnia unikalny układ połączeń w siatce sześciokątnej, gdzie każdy neuron jest równo oddalony od swoich sześciu sąsiadów.\n",
    "\n",
    "#### <span style=\"color:lightblue\"> Znaczenie w praktyce <span>\n",
    "\n",
    "Wybór topologii wpływa na sposób, w jaki dane wejściowe są klasyfikowane i reprezentowane na mapie Kohonena. Topologia sześciokątna zwykle oferuje lepsze pokrycie i może być bardziej efektywna w zachowywaniu topologicznych relacji w danych, podczas gdy prostokątna jest prostsza w implementacji i interpretacji.\n",
    "\n",
    "#### <span style=\"color:lightblue\">  Implementacja <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_distance(self, a, b):\n",
    "    ax, ay = a\n",
    "    bx, by = b\n",
    "    if self.topology == 'rectangular':\n",
    "        return np.sqrt((ax - bx) ** 2 + (ay - by) ** 2)\n",
    "    elif self.topology == 'hexagonal':\n",
    "        dx = bx - ax\n",
    "        dy = by - ay\n",
    "        return max(abs(dx), abs(dy), abs(dx + dy))\n",
    "    else:\n",
    "        raise ValueError(\"Dostępne są tylko dwie topologie: rectangular | hexagonal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#458dc8\"> 7. Wizualizacje + Metody oceny <span>\n",
    "\n",
    "Klasa `KOH` oferuje różne funkcje do wizualizacji i oceny wydajności mapy cech Kohonena. Poniżej znajduje si szczegółowy opis trzech kluczowych metod: `plot_kohonen_map`, `evaluate_accuracy` oraz `calculate_silhouette_score`.\n",
    "\n",
    "#### <span style=\"color:orange\"> Mapa Kohonena <span>\n",
    "\n",
    "Metoda `plot_kohonen_map` służy do wizualizacji mapy Kohonena, przedstawiając neurony jako siatkę kolorowanych komórek, gdzie kolory odpowiadają różnym przypisanym klasom. Umożliwia to szybką ocenę sposobu, w jaki dane są klasyfikowane przez sieć.\n",
    "\n",
    "\n",
    "#### <span style=\"color:orange\"> Evaluate Accuracy <span>\n",
    "\n",
    "Metoda `evaluate_accuracy` oblicza dokładność mapy Kohonena poprzez porównanie przewidywanych etykiet z rzeczywistymi etykietami testowymi. To narzędzie jest istotne do oceny jakości klasyfikacji wykonanej przez sieć.\n",
    "\n",
    "Dokładność jest definiowana jako stosunek liczby poprawnie sklasyfikowanych próbek do ogólnej liczby próbek:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\sum_{i=1}^{N} \\mathbf{1}(y_i = \\hat{y}_i)}{N}\n",
    "$$\n",
    "\n",
    "gdzie $ y_i $ to rzeczywista etykieta, a $ \\hat{y}_i $ to przewidywana etykieta dla i-tej próbki.\n",
    "\n",
    "#### <span style=\"color:orange\"> Wskaźnik Silhouette <span>\n",
    "\n",
    "Metoda `calculate_silhouette_score` oblicza wskaźnik Silhouette dla danych klasyfikowanych przez mapę Kohonena. Jest to miara, jak dobrze dane są grupowane w klastry.\n",
    "\n",
    "Wskaźnik Silhouette jest średnią wartością wskaźnika Silhouette dla każdej próbki, gdzie:\n",
    "\n",
    "$$\n",
    "s = \\frac{b - a}{\\max(a, b)}\n",
    "$$\n",
    "\n",
    "- $ a $ jest średnią odległością między próbką a wszystkimi innymi punktami w tym samym klastrze,\n",
    "- $ b $ jest minimalną średnią odległością od próbki do punktów w różnym klastrze.\n",
    "\n",
    "Te trzy metody są kluczowe dla oceny i interpretacji wyników generowanych przez samoorganizującą się mapę Kohonena, dostarczając informacji o jakości klasyfikacji, wizualnej reprezentacji klastrów oraz optymalności grupowania danych.\n",
    "\n",
    "# <span style=\"color:#458dc8\"> Praktyczne zastosowanie znaleźć można w moim dodatkowym pliku KOH2 <span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
